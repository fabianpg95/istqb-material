{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Introduction This guide purpose\u2019s is to provide the tester some information and guidance about ISTQB Foundation Level.","title":"Introduction"},{"location":"#introduction","text":"This guide purpose\u2019s is to provide the tester some information and guidance about ISTQB Foundation Level.","title":"Introduction"},{"location":"test_ref/","text":"External resources: Udemy ISTQB Foundation Level (2021) ISTQB Official Website ISTQB Foundation Level","title":"References"},{"location":"test_ref/#external-resources","text":"Udemy ISTQB Foundation Level (2021) ISTQB Official Website ISTQB Foundation Level","title":"External resources:"},{"location":"fundamentals/1.-content/","text":"Fundamentals of Testing 1.1 - What is testing? 1.1.1 - Typical Objectives of Testing 1.1.2 - Testing and Debugging 1.2 - Why is testing necessary? 1.2.1 - Testing's contribution to success 1.2.2 - Quality Assurance and Testing 1.2.3 - Errors, Defects, and Failures 1.2.4 - Defects, Root Causes and Effects 1.3 - Seven Testing Principles 1.4 - Test Process 1.4.1 - Test Process in Context 1.4.2 - Test Activities and Tasks 1.4.3 - Test Work Products 1.4.4 - Traceability between the Test Basis and Test Work Products 1.5 - The Psycology of Testing 1.5.1 - Human Psychology and Testing 1.5.2 - Tester's and Developer's Mindsets","title":"1.-Content"},{"location":"fundamentals/1.-content/#fundamentals-of-testing","text":"1.1 - What is testing? 1.1.1 - Typical Objectives of Testing 1.1.2 - Testing and Debugging 1.2 - Why is testing necessary? 1.2.1 - Testing's contribution to success 1.2.2 - Quality Assurance and Testing 1.2.3 - Errors, Defects, and Failures 1.2.4 - Defects, Root Causes and Effects 1.3 - Seven Testing Principles 1.4 - Test Process 1.4.1 - Test Process in Context 1.4.2 - Test Activities and Tasks 1.4.3 - Test Work Products 1.4.4 - Traceability between the Test Basis and Test Work Products 1.5 - The Psycology of Testing 1.5.1 - Human Psychology and Testing 1.5.2 - Tester's and Developer's Mindsets","title":"Fundamentals of Testing"},{"location":"fundamentals/1.1-what-is-testing/","text":"What is testing ? \"Software testing is a way to asses the quality of the software and to reduce the risk of software failures in operation.\" Note ISTQB definition: \"Testing is the process consisting of all lifecycle activities (static and dynamic) concerned with planning preparation and evaluation pf a component system and related work products to determine that they satisfy specified requirements for purpose and to detect defects.\" A common misconception of testing is that it only consists of running tests, executing the software and checking the results. However, test activities are before and after test execution. 1.1.1 Typical objectives of testing Verify requirements Prevent defects Find defects and failures Gain confidence in system Reduce the level of risk Providing information for decision making Compliance 1.1.2 Testing and debugging Debugging: Localizes the defect, fixes the defect and checks that the fix has been applied correctly. (developer) Testing: Confirms that the fix works as intended in the system. (Tester)","title":"1.1-What is testing?"},{"location":"fundamentals/1.1-what-is-testing/#what-is-testing","text":"\"Software testing is a way to asses the quality of the software and to reduce the risk of software failures in operation.\" Note ISTQB definition: \"Testing is the process consisting of all lifecycle activities (static and dynamic) concerned with planning preparation and evaluation pf a component system and related work products to determine that they satisfy specified requirements for purpose and to detect defects.\" A common misconception of testing is that it only consists of running tests, executing the software and checking the results. However, test activities are before and after test execution.","title":"What is testing?"},{"location":"fundamentals/1.1-what-is-testing/#111-typical-objectives-of-testing","text":"Verify requirements Prevent defects Find defects and failures Gain confidence in system Reduce the level of risk Providing information for decision making Compliance","title":"1.1.1 Typical objectives of testing"},{"location":"fundamentals/1.1-what-is-testing/#112-testing-and-debugging","text":"Debugging: Localizes the defect, fixes the defect and checks that the fix has been applied correctly. (developer) Testing: Confirms that the fix works as intended in the system. (Tester)","title":"1.1.2 Testing and debugging"},{"location":"fundamentals/1.2-why-test-neces/","text":"1.2.1 Testing's contributions to success 1.2.2 Quality Assurance and Testing Quality Management All activities that direct and control quality in organization. Quality Assurance Adherence to proper process. Quality Control Includes testing and other activities to achieve quality. 1.2.3 'Errors', 'defects' and 'failures' Software systems are increasingly complex, often systems are connected to many other systems. Development of these complex systems requires a great deal of time, skill and effort, and during this process, human beings can make errors or mistakes . Errors can lead to the introduction of a defect (fault or bug) in the software code or in any other work product. Errors may occur due to many reasons such as: Time pressure. Humans are not perfect, so always there is a risk to make errors or mistakes. Skills not match with the architecture or technologies Complexity of system Changing technologies If a Defect has been introduced into the code after the code is executed it could cause a failure . (A failure occurs within the system). Failures may also caused by environmental conditions Diagram: 1.2.4 Defects Root Causes and Effects The root causes of defects are the earliest actions or conditions that contributed to creating the defects. Typical RCA include: Unclear requirement Missing requirement Wrong requirement Code logic error Invalid data","title":"1.2-Why is testing necessary?"},{"location":"fundamentals/1.2-why-test-neces/#121-testings-contributions-to-success","text":"","title":"1.2.1 Testing's contributions to success"},{"location":"fundamentals/1.2-why-test-neces/#122-quality-assurance-and-testing","text":"","title":"1.2.2 Quality Assurance and Testing"},{"location":"fundamentals/1.2-why-test-neces/#quality-management","text":"All activities that direct and control quality in organization.","title":"Quality Management"},{"location":"fundamentals/1.2-why-test-neces/#quality-assurance","text":"Adherence to proper process.","title":"Quality Assurance"},{"location":"fundamentals/1.2-why-test-neces/#quality-control","text":"Includes testing and other activities to achieve quality.","title":"Quality Control"},{"location":"fundamentals/1.2-why-test-neces/#123-errors-defects-and-failures","text":"Software systems are increasingly complex, often systems are connected to many other systems. Development of these complex systems requires a great deal of time, skill and effort, and during this process, human beings can make errors or mistakes . Errors can lead to the introduction of a defect (fault or bug) in the software code or in any other work product. Errors may occur due to many reasons such as: Time pressure. Humans are not perfect, so always there is a risk to make errors or mistakes. Skills not match with the architecture or technologies Complexity of system Changing technologies If a Defect has been introduced into the code after the code is executed it could cause a failure . (A failure occurs within the system). Failures may also caused by environmental conditions","title":"1.2.3 'Errors', 'defects' and 'failures'"},{"location":"fundamentals/1.2-why-test-neces/#diagram","text":"","title":"Diagram:"},{"location":"fundamentals/1.2-why-test-neces/#124-defects-root-causes-and-effects","text":"The root causes of defects are the earliest actions or conditions that contributed to creating the defects. Typical RCA include: Unclear requirement Missing requirement Wrong requirement Code logic error Invalid data","title":"1.2.4 Defects Root Causes and Effects"},{"location":"fundamentals/1.3-seven-test-princ/","text":"Over the last 50 years, there have been number of testing principles that offer general guidelines but the ISTQB Syllabus covers 7 principles: Principle 1: Testing shows presence of defects, not their absence. Testing can show that defects are present, but it cannot prove that no defects are remaining. Note Even when no defects are found during testing, it can\u00b4t be proved that software is defect-free. Always exist risks. Principle 2: Exhaustive testing is impossible Testing everything (all combinations of inputs and preconditions) is not possible, except for trivial cases. Rather than attempting to test exhaustively, the effort should be focus on risks analysis, test techniques and priorities. Note It is not possible to test all possible combinations of data input in most of the circunstances. Exhaustive testing is a test approach in which all possible data combinations are used, including the implicit in the state of the software, so is not feasible. Principle 3: Early testing saves time and money The following diagram shows that the relative cost of fixing the defects increase with each project phase. Principle 4: Defects cluster together Experience shows that in general, a small number of software modules contains most of the defects discovered during pre-release testing or are responsible for most of the operational failures. Defects are clustered in modules that are: More complex Larger More prone to changes Have been worked on by many different developers over time Note 80% of defects come from 20% of the modules (Pareto principle applied to software testing). Principle 5: Beware of Pesticide paradox If the same tests are repeated over and over again, eventually these tests no longer find any new defects. If the same test cases fail to find any new defects, running the same test cases, again and again, will eventually leave the tester with a false sense of security.(The same apply for regression tests) Recommendations: Review test cases regularly Add more relevant new test cases to exercise different parts of the software and remove the test cases which are not required. Consider the value of running tests in each regression run. Make sure there is a value-add from the effort. Principle 6: Testing is context dependent Testing is done differently in different contexts. For example, safety-critical software is tested differently from e-commerce software. Recommendations: Same set of testing activities are not applicable for all applications. Testing is done for different applications. Risk must be considered in determining the type of testing that is needed. Principle 7: Absense-of-error fallacy It is a mistake to expect that just finding and fixing a large number of defects will ensure the success of a system.","title":"1.3- 7 test principles"},{"location":"fundamentals/1.3-seven-test-princ/#principle-1-testing-shows-presence-of-defects-not-their-absence","text":"Testing can show that defects are present, but it cannot prove that no defects are remaining. Note Even when no defects are found during testing, it can\u00b4t be proved that software is defect-free. Always exist risks.","title":"Principle 1: Testing shows presence of defects, not their absence."},{"location":"fundamentals/1.3-seven-test-princ/#principle-2-exhaustive-testing-is-impossible","text":"Testing everything (all combinations of inputs and preconditions) is not possible, except for trivial cases. Rather than attempting to test exhaustively, the effort should be focus on risks analysis, test techniques and priorities. Note It is not possible to test all possible combinations of data input in most of the circunstances. Exhaustive testing is a test approach in which all possible data combinations are used, including the implicit in the state of the software, so is not feasible.","title":"Principle 2: Exhaustive testing is impossible"},{"location":"fundamentals/1.3-seven-test-princ/#principle-3-early-testing-saves-time-and-money","text":"The following diagram shows that the relative cost of fixing the defects increase with each project phase.","title":"Principle 3: Early testing saves time and money"},{"location":"fundamentals/1.3-seven-test-princ/#principle-4-defects-cluster-together","text":"Experience shows that in general, a small number of software modules contains most of the defects discovered during pre-release testing or are responsible for most of the operational failures. Defects are clustered in modules that are: More complex Larger More prone to changes Have been worked on by many different developers over time Note 80% of defects come from 20% of the modules (Pareto principle applied to software testing).","title":"Principle 4: Defects cluster together"},{"location":"fundamentals/1.3-seven-test-princ/#principle-5-beware-of-pesticide-paradox","text":"If the same tests are repeated over and over again, eventually these tests no longer find any new defects. If the same test cases fail to find any new defects, running the same test cases, again and again, will eventually leave the tester with a false sense of security.(The same apply for regression tests) Recommendations: Review test cases regularly Add more relevant new test cases to exercise different parts of the software and remove the test cases which are not required. Consider the value of running tests in each regression run. Make sure there is a value-add from the effort.","title":"Principle 5: Beware of Pesticide paradox"},{"location":"fundamentals/1.3-seven-test-princ/#principle-6-testing-is-context-dependent","text":"Testing is done differently in different contexts. For example, safety-critical software is tested differently from e-commerce software. Recommendations: Same set of testing activities are not applicable for all applications. Testing is done for different applications. Risk must be considered in determining the type of testing that is needed.","title":"Principle 6: Testing is context dependent"},{"location":"fundamentals/1.3-seven-test-princ/#principle-7-absense-of-error-fallacy","text":"It is a mistake to expect that just finding and fixing a large number of defects will ensure the success of a system.","title":"Principle 7: Absense-of-error fallacy"},{"location":"fundamentals/1.4-test-process/","text":"(ISO /IEC/IEEE 29119 -2) provides more information about test processes. Considerations Contextual factor that influence the test process for an organization include, but not are limited to: SDLC model and project methodologies being used. Test levels and test types being considered. Product and project risks Business domain Operational constraints: Budget and resources Timescales Complexity Organizational policies and standards Regulatory contracts Test activities and tasks","title":"1.4-Test process"},{"location":"fundamentals/1.4-test-process/#considerations","text":"Contextual factor that influence the test process for an organization include, but not are limited to: SDLC model and project methodologies being used. Test levels and test types being considered. Product and project risks Business domain Operational constraints: Budget and resources Timescales Complexity Organizational policies and standards Regulatory contracts","title":"Considerations"},{"location":"fundamentals/1.4-test-process/#test-activities-and-tasks","text":"","title":"Test activities and tasks"},{"location":"fundamentals/1.5-psyco-of-testing/","text":"1.5.1 Human Psychology and Testing Constructive way: Testers and managers need to have good interpersonal skills to be able to communicate effectively about defects, failures, test results, test progress and risks. Start with collaboration rather than battles. Emphasize the benefits of testing. Communicate test results and other findings in a neutral way. Try to understand how the other person feels. 1.2.1 Tester's and Developer's mindset Independent Testers: Bring a perspective that is different thant the one of its product authors (i.e business analysts, product owners, designers and programmers)","title":"1.5-Psycology of testing"},{"location":"fundamentals/1.5-psyco-of-testing/#151-human-psychology-and-testing","text":"","title":"1.5.1 Human Psychology and Testing"},{"location":"fundamentals/1.5-psyco-of-testing/#constructive-way","text":"Testers and managers need to have good interpersonal skills to be able to communicate effectively about defects, failures, test results, test progress and risks. Start with collaboration rather than battles. Emphasize the benefits of testing. Communicate test results and other findings in a neutral way. Try to understand how the other person feels.","title":"Constructive way:"},{"location":"fundamentals/1.5-psyco-of-testing/#121-testers-and-developers-mindset","text":"","title":"1.2.1 Tester's and Developer's mindset"},{"location":"fundamentals/1.5-psyco-of-testing/#independent-testers","text":"Bring a perspective that is different thant the one of its product authors (i.e business analysts, product owners, designers and programmers)","title":"Independent Testers:"},{"location":"fundamentals/defect_report/","text":"What is a defect report? Documentation of the occurrence, nature, and status of a defect . If we use an example like Facebook, these would be the priorities. Bug priority: Critical: Login isn\u2019t working-Application crashes in Home page \u2013 Wrong cart value High: Login page responds slowly \u2013 User is not able to add profile image Medium: Some pages have poor performance- Portrait mode isn\u2019t working correctly Low: Spelling mistakes \u2013 Image misalignment Example of a defect report:","title":"Defect report"},{"location":"fundamentals/defect_report/#what-is-a-defect-report","text":"Documentation of the occurrence, nature, and status of a defect . If we use an example like Facebook, these would be the priorities.","title":"What is a defect report?"},{"location":"fundamentals/defect_report/#bug-priority","text":"Critical: Login isn\u2019t working-Application crashes in Home page \u2013 Wrong cart value High: Login page responds slowly \u2013 User is not able to add profile image Medium: Some pages have poor performance- Portrait mode isn\u2019t working correctly Low: Spelling mistakes \u2013 Image misalignment","title":"Bug priority:"},{"location":"fundamentals/defect_report/#example-of-a-defect-report","text":"","title":"Example of a defect report:"},{"location":"fundamentals/defect_types/","text":"Types 1-Functional: Forgot password functionality isn\u2019t working. 2-Visual (UI): 3-Content: 4-Performance: Videos take too much time to play. 5-Suggestion: The font of the placeholder should be bigger Status","title":"Defect types"},{"location":"fundamentals/defect_types/#types","text":"","title":"Types"},{"location":"fundamentals/defect_types/#1-functional","text":"Forgot password functionality isn\u2019t working.","title":"1-Functional:"},{"location":"fundamentals/defect_types/#2-visual-ui","text":"","title":"2-Visual (UI):"},{"location":"fundamentals/defect_types/#3-content","text":"","title":"3-Content:"},{"location":"fundamentals/defect_types/#4-performance","text":"Videos take too much time to play.","title":"4-Performance:"},{"location":"fundamentals/defect_types/#5-suggestion","text":"The font of the placeholder should be bigger Status","title":"5-Suggestion:"},{"location":"fundamentals/test_intro/","text":"Definition of 'testing': \"Software testing is a way to asses the quality of the software and to reduce the risk of software failures in operation.\" Note ISTQB definition: \"Testing is the process consisting of all lifecycle activities (static and dynamic) concerned with planning preparation and evaluation pf a component system and related work products to determine that they satisfy specified requirements for purpose and to detect defects.\" A common misconception of testing is that it only consists of running tests, executing the software and checking the results. However, test activities are before and after test execution. Example: Planning and control Choose test conditions Designing test cases Evaluation of completion criteria Reporting the testing progress and results Typical objectives of testing Verify requirements Prevent defects Find defects and failures Gain confidence in system Reduce the level of risk Providing information for decision making Compliance 'Errors', 'defects' and 'failures' Software systems are increasingly complex, often systems are connected to many other systems. Development of these complex systems requires a great deal of time, skill and effort, and during this process, human beings can make errors or mistakes . Errors can lead to the introduction of a defect (fault or bug) in the software code or in any other work product. Errors may occur due to many reasons such as: Time pressure. Humans are not perfect, so always there is a risk to make errors or mistakes. Skills not match with the architecture or technologies Complexity of system Changing technologies If a Defect has been introduced into the code after the code is executed it could cause a failure . (A failure occurs within the system). Failures may also caused by environmental conditions Diagram: gst Root Cause Analysis The root causes of defects are the earliest actions or conditions that contributed to creating the defects. Typical RCA include: Unclear requirement Missing requirement Wrong requirement Code logic error Invalid data","title":"Test intro"},{"location":"fundamentals/test_intro/#definition-of-testing","text":"\"Software testing is a way to asses the quality of the software and to reduce the risk of software failures in operation.\" Note ISTQB definition: \"Testing is the process consisting of all lifecycle activities (static and dynamic) concerned with planning preparation and evaluation pf a component system and related work products to determine that they satisfy specified requirements for purpose and to detect defects.\" A common misconception of testing is that it only consists of running tests, executing the software and checking the results. However, test activities are before and after test execution. Example: Planning and control Choose test conditions Designing test cases Evaluation of completion criteria Reporting the testing progress and results","title":"Definition of 'testing':"},{"location":"fundamentals/test_intro/#typical-objectives-of-testing","text":"Verify requirements Prevent defects Find defects and failures Gain confidence in system Reduce the level of risk Providing information for decision making Compliance","title":"Typical objectives of testing"},{"location":"fundamentals/test_intro/#errors-defects-and-failures","text":"Software systems are increasingly complex, often systems are connected to many other systems. Development of these complex systems requires a great deal of time, skill and effort, and during this process, human beings can make errors or mistakes . Errors can lead to the introduction of a defect (fault or bug) in the software code or in any other work product. Errors may occur due to many reasons such as: Time pressure. Humans are not perfect, so always there is a risk to make errors or mistakes. Skills not match with the architecture or technologies Complexity of system Changing technologies If a Defect has been introduced into the code after the code is executed it could cause a failure . (A failure occurs within the system). Failures may also caused by environmental conditions","title":"'Errors', 'defects' and 'failures'"},{"location":"fundamentals/test_intro/#diagram","text":"gst","title":"Diagram:"},{"location":"fundamentals/test_intro/#root-cause-analysis","text":"The root causes of defects are the earliest actions or conditions that contributed to creating the defects. Typical RCA include: Unclear requirement Missing requirement Wrong requirement Code logic error Invalid data","title":"Root Cause Analysis"},{"location":"software_lifecycle/1.-content/","text":"Software Lifecycle 2.1 - Learning Objectives for Testing Throughout the Software 2.1.1 - Software Development and Software Testing 2.1.2 - Software Development Lifecycle Models in Context 2.2 - Test Levels 2.2.1 - Component / Unit testing 2.2. - Integration Testing 2.2.3 - System Testing 2.2.4 - Acceptance Testing 2.3 - Test Types 2.3.1 - Functional Testing 2.3.2 - Non-functional Testing 2.3.3 - White Box testing 2.3.4 - Change-related testing 2.3.5 - Test Types and Test Levels 2.4 - Maintenance Testing 2.4.1 - Triggers and Maintenance 2.4.2 - Impact Analysis and Maintenance","title":"1.-Content"},{"location":"software_lifecycle/1.-content/#software-lifecycle","text":"2.1 - Learning Objectives for Testing Throughout the Software 2.1.1 - Software Development and Software Testing 2.1.2 - Software Development Lifecycle Models in Context 2.2 - Test Levels 2.2.1 - Component / Unit testing 2.2. - Integration Testing 2.2.3 - System Testing 2.2.4 - Acceptance Testing 2.3 - Test Types 2.3.1 - Functional Testing 2.3.2 - Non-functional Testing 2.3.3 - White Box testing 2.3.4 - Change-related testing 2.3.5 - Test Types and Test Levels 2.4 - Maintenance Testing 2.4.1 - Triggers and Maintenance 2.4.2 - Impact Analysis and Maintenance","title":"Software Lifecycle"},{"location":"software_lifecycle/2.1-obj-testing-softw/","text":"2.1 - Learning Objectives for Testing Throughout the Software 2.1.1 - Software Development and Software Testing 2.1.2 - Software Development Lifecycle Models in Context","title":"2.1-Objectives of testing"},{"location":"software_lifecycle/2.1-obj-testing-softw/#21-learning-objectives-for-testing-throughout-the-software","text":"","title":"2.1 - Learning Objectives for Testing Throughout the Software"},{"location":"software_lifecycle/2.1-obj-testing-softw/#211-software-development-and-software-testing","text":"","title":"2.1.1 - Software Development and Software Testing"},{"location":"software_lifecycle/2.1-obj-testing-softw/#212-software-development-lifecycle-models-in-context","text":"","title":"2.1.2 - Software Development Lifecycle Models in Context"},{"location":"software_lifecycle/2.2-test-levels/","text":"2.2.1 - Component / Unit testingt 2.2.2 - Integration Testing 2.2.3 - System Testing 2.2.4 - Acceptance Testing","title":"2.2-Test levels"},{"location":"software_lifecycle/2.2-test-levels/#221-component-unit-testingt","text":"","title":"2.2.1 - Component / Unit testingt"},{"location":"software_lifecycle/2.2-test-levels/#222-integration-testing","text":"","title":"2.2.2 - Integration Testing"},{"location":"software_lifecycle/2.2-test-levels/#223-system-testing","text":"","title":"2.2.3 - System Testing"},{"location":"software_lifecycle/2.2-test-levels/#224-acceptance-testing","text":"","title":"2.2.4 - Acceptance Testing"},{"location":"software_lifecycle/2.3-test-types/","text":"2.3.1 - Functional Testing 2.3.2 - Non-functional Testing 2.3.3 - White Box Testing 2.3.4 - Change-related Testing 2.3.5 - Test Types and Test Levels","title":"2.3-Test types"},{"location":"software_lifecycle/2.3-test-types/#231-functional-testing","text":"","title":"2.3.1 - Functional Testing"},{"location":"software_lifecycle/2.3-test-types/#232-non-functional-testing","text":"","title":"2.3.2 - Non-functional Testing"},{"location":"software_lifecycle/2.3-test-types/#233-white-box-testing","text":"","title":"2.3.3 - White Box Testing"},{"location":"software_lifecycle/2.3-test-types/#234-change-related-testing","text":"","title":"2.3.4 - Change-related Testing"},{"location":"software_lifecycle/2.3-test-types/#235-test-types-and-test-levels","text":"","title":"2.3.5 - Test Types and Test Levels"},{"location":"software_lifecycle/2.4-maintenance-testing/","text":"2.4.1 - Triggers and Maintenance 2.4.2 - Impact Analysis and Maintenance","title":"2.4-Maintenance testing"},{"location":"software_lifecycle/2.4-maintenance-testing/#241-triggers-and-maintenance","text":"","title":"2.4.1 - Triggers and Maintenance"},{"location":"software_lifecycle/2.4-maintenance-testing/#242-impact-analysis-and-maintenance","text":"","title":"2.4.2 - Impact Analysis and Maintenance"},{"location":"software_lifecycle/dev_models/","text":"Software Development Life Cycle (SDLC A SDLC describes the type of activities performed at each stage in a software development project. There are a number of different software development lifecycle models, each of which requires different approaches to testing. Software Development Process Models. ISTQB Syllabus divide the models into 3 categories: 1.- Traditional (optional, and default for Project management) 2.- Sequential 3.- Iterative and Incremental Traditional SDLC The traditional SDLC is a model used in project management that defines the stages include in an information system development project, from an initial feasibility study to the maintenance of the completed application. Sequential Development model This model describes the software development process as a linear, sequential flow of activities. That means that any phase in the development process should only begin when the previous phase is completed. Examples: Waterfall model V-model Explanation: The activities on the left-hand side of the V-model focuses on work-product creation for elaborating the initial requirements and then providing more technical detail for the development. ( Static testing ) The activities for the right-hand focuses on the testing activities. ( Dynamic testing ) Verification helps to ensure that the product is built in the right way.( the process ) Validation checks that the right product is being built. Iterative and incremental model Works on smaller incremental developments. ( iterations ) Good practices for Software Development and Software Testing: For every development activity, there is a corresponding testing activity. Each test level has test objectives specific to that level The analysis and design of tests for a given test level should begin during the corresponding development activity. Testers participate in discussions to define and refine requirements and design.","title":"Dev models"},{"location":"software_lifecycle/dev_models/#software-development-life-cycle-sdlc","text":"A SDLC describes the type of activities performed at each stage in a software development project. There are a number of different software development lifecycle models, each of which requires different approaches to testing.","title":"Software Development Life Cycle (SDLC"},{"location":"software_lifecycle/dev_models/#software-development-process-models","text":"ISTQB Syllabus divide the models into 3 categories: 1.- Traditional (optional, and default for Project management) 2.- Sequential 3.- Iterative and Incremental","title":"Software Development Process Models."},{"location":"software_lifecycle/dev_models/#traditional-sdlc","text":"The traditional SDLC is a model used in project management that defines the stages include in an information system development project, from an initial feasibility study to the maintenance of the completed application.","title":"Traditional SDLC"},{"location":"software_lifecycle/dev_models/#sequential-development-model","text":"This model describes the software development process as a linear, sequential flow of activities. That means that any phase in the development process should only begin when the previous phase is completed. Examples: Waterfall model V-model Explanation: The activities on the left-hand side of the V-model focuses on work-product creation for elaborating the initial requirements and then providing more technical detail for the development. ( Static testing ) The activities for the right-hand focuses on the testing activities. ( Dynamic testing ) Verification helps to ensure that the product is built in the right way.( the process ) Validation checks that the right product is being built.","title":"Sequential Development model"},{"location":"software_lifecycle/dev_models/#iterative-and-incremental-model","text":"Works on smaller incremental developments. ( iterations )","title":"Iterative and incremental model"},{"location":"software_lifecycle/dev_models/#good-practices-for-software-development-and-software-testing","text":"For every development activity, there is a corresponding testing activity. Each test level has test objectives specific to that level The analysis and design of tests for a given test level should begin during the corresponding development activity. Testers participate in discussions to define and refine requirements and design.","title":"Good practices for Software Development and Software Testing:"},{"location":"software_lifecycle/test_levels/","text":"For every test level, a suitable test environment is required, for example for Acceptance is Production and for Unit tests is the development environment. Unit/component testing Focuses on components that are separately testable. Typical test basis Detailed design Code Data model Component specification Typical defects and failures: Incorrect functionality Data flow problems Incorrect code and logic Typical test objects: Components, units or modules Code and data structures Classes Database modules Summary: Performed by developers who have coded the component. For agile teams, Test Driven Development (TDD) is the most common practice. Developed and tested using development environment. Integration testing Focuses on the interaction between components or systems. This stage should be focuses on the communication between the modules, not the functionality of the individual modules because that part should be covered in unit tests. Typical test basis Architecture at component or system level Sequence diagrams Interface and communication protocol specifications Use cases Workflows Typical defects Interfaces mismatch Failures in communication between components Incorrect timing, sequencing or interface calls Typical test objects Sub-systems Database implementation Infrastructure Interfaces API\u00b4s Microservices System testing Typical test basis Use cases Epics and user stories Models of system behavior State diagrams System and user manuals Typical defects Incorrect calculations Incorrect or unexpected system functional or non-functional behavior Failure of the system to work properly Failure of the system to work as described in system and user manual Typical test objects Applications Hardware/Software systems O.S System Under Test (SUT) Acceptance testing Then purpose of acceptance testing is to validate the system is fit for purpose. Typical test basis Business processes User or business requirements Risk analysis reports Installation procedures Legal contracts or standards Typical defects System workflows don\u00b4t meet business or user requirements Business rules are not implemented correctly Non-functional failures such as security vulnerabilities, performance efficiency or improper operations. Typical test objects System Under Test Forms Reports Recovery systems and hot sites Existing and converted production data Alpha and Beta testing: Alpha Is performed at the developing organization\u00b4s site, not by the development team, but by potencial or existing customer, operators or independent test team. Beta Is performed by potential or existingn customer or operators at their own locations. Note Beta testing may come after Alpha testing or may occur without any preceding alpha testing.","title":"Test levels"},{"location":"software_lifecycle/test_levels/#unitcomponent-testing","text":"Focuses on components that are separately testable.","title":"Unit/component testing"},{"location":"software_lifecycle/test_levels/#typical-test-basis","text":"Detailed design Code Data model Component specification","title":"Typical test basis"},{"location":"software_lifecycle/test_levels/#typical-defects-and-failures","text":"Incorrect functionality Data flow problems Incorrect code and logic","title":"Typical defects and failures:"},{"location":"software_lifecycle/test_levels/#typical-test-objects","text":"Components, units or modules Code and data structures Classes Database modules","title":"Typical test objects:"},{"location":"software_lifecycle/test_levels/#summary","text":"Performed by developers who have coded the component. For agile teams, Test Driven Development (TDD) is the most common practice. Developed and tested using development environment.","title":"Summary:"},{"location":"software_lifecycle/test_levels/#integration-testing","text":"Focuses on the interaction between components or systems. This stage should be focuses on the communication between the modules, not the functionality of the individual modules because that part should be covered in unit tests.","title":"Integration testing"},{"location":"software_lifecycle/test_levels/#typical-test-basis_1","text":"Architecture at component or system level Sequence diagrams Interface and communication protocol specifications Use cases Workflows","title":"Typical test basis"},{"location":"software_lifecycle/test_levels/#typical-defects","text":"Interfaces mismatch Failures in communication between components Incorrect timing, sequencing or interface calls","title":"Typical defects"},{"location":"software_lifecycle/test_levels/#typical-test-objects_1","text":"Sub-systems Database implementation Infrastructure Interfaces API\u00b4s Microservices","title":"Typical test objects"},{"location":"software_lifecycle/test_levels/#system-testing","text":"","title":"System testing"},{"location":"software_lifecycle/test_levels/#typical-test-basis_2","text":"Use cases Epics and user stories Models of system behavior State diagrams System and user manuals","title":"Typical test basis"},{"location":"software_lifecycle/test_levels/#typical-defects_1","text":"Incorrect calculations Incorrect or unexpected system functional or non-functional behavior Failure of the system to work properly Failure of the system to work as described in system and user manual","title":"Typical defects"},{"location":"software_lifecycle/test_levels/#typical-test-objects_2","text":"Applications Hardware/Software systems O.S System Under Test (SUT)","title":"Typical test objects"},{"location":"software_lifecycle/test_levels/#acceptance-testing","text":"Then purpose of acceptance testing is to validate the system is fit for purpose.","title":"Acceptance testing"},{"location":"software_lifecycle/test_levels/#typical-test-basis_3","text":"Business processes User or business requirements Risk analysis reports Installation procedures Legal contracts or standards","title":"Typical test basis"},{"location":"software_lifecycle/test_levels/#typical-defects_2","text":"System workflows don\u00b4t meet business or user requirements Business rules are not implemented correctly Non-functional failures such as security vulnerabilities, performance efficiency or improper operations.","title":"Typical defects"},{"location":"software_lifecycle/test_levels/#typical-test-objects_3","text":"System Under Test Forms Reports Recovery systems and hot sites Existing and converted production data","title":"Typical test objects"},{"location":"software_lifecycle/test_levels/#alpha-and-beta-testing","text":"Alpha Is performed at the developing organization\u00b4s site, not by the development team, but by potencial or existing customer, operators or independent test team. Beta Is performed by potential or existingn customer or operators at their own locations. Note Beta testing may come after Alpha testing or may occur without any preceding alpha testing.","title":"Alpha and Beta testing:"},{"location":"static_test/1.-content/","text":"Static Testing 3.1 - Static Testing Basics 3.1.1 - Work Products that can be examined by Static Testing 3.1.2 - Benefits of Static Testing 3.1.3 - Differences between Static and Dynamic Testing 3.2 - Review Process 3.2.1 - Work Product Review Process 3.2.2 - Roles and Responsibilities in a formal review 3.2.3 - Review Types 3.2.4 - Applying Review Techniques 3.2.5 - Success Factors for Reviews","title":"1.-Content"},{"location":"static_test/1.-content/#static-testing","text":"3.1 - Static Testing Basics 3.1.1 - Work Products that can be examined by Static Testing 3.1.2 - Benefits of Static Testing 3.1.3 - Differences between Static and Dynamic Testing 3.2 - Review Process 3.2.1 - Work Product Review Process 3.2.2 - Roles and Responsibilities in a formal review 3.2.3 - Review Types 3.2.4 - Applying Review Techniques 3.2.5 - Success Factors for Reviews","title":"Static Testing"},{"location":"static_test/3.1-stat-test-bas/","text":"3.1.1 - Work Products that can be examined by Static Testing 3.1.2 - Benefits of Static Testing When applied early in the software development lifecycle, enables the early detection of defects before dynamic testing is performed, examples: in requirements design specifications reviews backlog refinement, etc. Defects found early are often much cheaper to remove than defects found later in the lifecycle, especially when the software is deployed and in active use. Additional benefits of static testing may include: Detecting and correcting defects more efficiently, and prior to dynamic test execution Identifying defects which are not easily found by dynamic testing Preventing defects in design or coding by uncovering inconsistencies, ambiguities, contradictions, omissions, inaccuracies, and redundancies in requirements Increasing development productivity (e.g., due to improved design, more maintainable code) Reducing development cost and time Reducing testing cost and time Reducing total cost of quality over the software\u2019s lifetime, due to fewer failures later in the lifecycle or after delivery into operation Improving communication between team members in the course of participating in reviews 3.1.3 - Differences between Static and Dynamic Testing","title":"3.1-Static testing basics"},{"location":"static_test/3.1-stat-test-bas/#311-work-products-that-can-be-examined-by-static-testing","text":"","title":"3.1.1 - Work Products that can be examined by Static Testing"},{"location":"static_test/3.1-stat-test-bas/#312-benefits-of-static-testing","text":"When applied early in the software development lifecycle, enables the early detection of defects before dynamic testing is performed, examples: in requirements design specifications reviews backlog refinement, etc. Defects found early are often much cheaper to remove than defects found later in the lifecycle, especially when the software is deployed and in active use.","title":"3.1.2 - Benefits of Static Testing"},{"location":"static_test/3.1-stat-test-bas/#additional-benefits-of-static-testing-may-include","text":"Detecting and correcting defects more efficiently, and prior to dynamic test execution Identifying defects which are not easily found by dynamic testing Preventing defects in design or coding by uncovering inconsistencies, ambiguities, contradictions, omissions, inaccuracies, and redundancies in requirements Increasing development productivity (e.g., due to improved design, more maintainable code) Reducing development cost and time Reducing testing cost and time Reducing total cost of quality over the software\u2019s lifetime, due to fewer failures later in the lifecycle or after delivery into operation Improving communication between team members in the course of participating in reviews","title":"Additional benefits of static testing may include:"},{"location":"static_test/3.1-stat-test-bas/#313-differences-between-static-and-dynamic-testing","text":"","title":"3.1.3 - Differences between Static and Dynamic Testing"},{"location":"static_test/3.2-review-process/","text":"3.2.1 - Work Product Review Process The review process comprises the following main activities: Planning Defining the scope, which includes the purpose of the review, what documents or parts of documents to review, and the quality characteristics to be evaluated Estimating effort and timeframe Identifying review characteristics such as the review type with roles, activities, and checklists Selecting the people to participate in the review and allocating roles Defining the entry and exit criteria for more formal review types (e.g., inspections) Checking that entry criteria are met (for more formal review types) Initiate review Distributing the work product (physically or by electronic means) and other material, such as issue log forms, checklists, and related work products Explaining the scope, objectives, process, roles, and work products to the participants Answering any questions that participants may have about the review Individual review (i.e., individual preparation) Reviewing all or part of the work product Noting potential defects, recommendations, and questions Issue communication and analysis Communicating identified potential defects (e.g., in a review meeting) Analyzing potential defects, assigning ownership and status to them Evaluating and documenting quality characteristics Evaluating the review findings against the exit criteria to make a review decision (reject; major changes needed. Fixing and reporting Creating defect reports for those findings that require changes to a work product Fixing defects found (typically done by the author) in the work product reviewed Communicating defects to the appropriate person or team (when found in a work product related to the work product reviewed) Recording updated status of defects (in formal reviews), potentially including the agreement of the comment originator Gathering metrics (for more formal review types) 3.2.2 - Roles and Responsibilities in a formal review 3.2.3 - Review Types 3.2.4 - Applying Review Techniques 3.2.5 - Success Factors for Reviews Each review has clear objectives, defined during review planning, and used as measurable exit criteria Review types are applied which are suitable to achieve the objectives and are appropriate to the type and level of software work products and participants Any review techniques used, such as checklist-based or role-based reviewing, are suitable for effective defect identification in the work product to be reviewed Any checklists used address the main risks and are up to date Large documents are written and reviewed in small chunks, so that quality control is exercised by providing authors early and frequent feedback on defects Participants have adequate time to prepare Reviews are scheduled with adequate notice","title":"3.2-Review process"},{"location":"static_test/3.2-review-process/#321-work-product-review-process","text":"The review process comprises the following main activities:","title":"3.2.1 - Work Product Review Process"},{"location":"static_test/3.2-review-process/#planning","text":"Defining the scope, which includes the purpose of the review, what documents or parts of documents to review, and the quality characteristics to be evaluated Estimating effort and timeframe Identifying review characteristics such as the review type with roles, activities, and checklists Selecting the people to participate in the review and allocating roles Defining the entry and exit criteria for more formal review types (e.g., inspections) Checking that entry criteria are met (for more formal review types)","title":"Planning"},{"location":"static_test/3.2-review-process/#initiate-review","text":"Distributing the work product (physically or by electronic means) and other material, such as issue log forms, checklists, and related work products Explaining the scope, objectives, process, roles, and work products to the participants Answering any questions that participants may have about the review","title":"Initiate review"},{"location":"static_test/3.2-review-process/#individual-review-ie-individual-preparation","text":"Reviewing all or part of the work product Noting potential defects, recommendations, and questions","title":"Individual review (i.e., individual preparation)"},{"location":"static_test/3.2-review-process/#issue-communication-and-analysis","text":"Communicating identified potential defects (e.g., in a review meeting) Analyzing potential defects, assigning ownership and status to them Evaluating and documenting quality characteristics Evaluating the review findings against the exit criteria to make a review decision (reject; major changes needed.","title":"Issue communication and analysis"},{"location":"static_test/3.2-review-process/#fixing-and-reporting","text":"Creating defect reports for those findings that require changes to a work product Fixing defects found (typically done by the author) in the work product reviewed Communicating defects to the appropriate person or team (when found in a work product related to the work product reviewed) Recording updated status of defects (in formal reviews), potentially including the agreement of the comment originator Gathering metrics (for more formal review types)","title":"Fixing and reporting"},{"location":"static_test/3.2-review-process/#322-roles-and-responsibilities-in-a-formal-review","text":"","title":"3.2.2 - Roles and Responsibilities in a formal review"},{"location":"static_test/3.2-review-process/#323-review-types","text":"","title":"3.2.3 - Review Types"},{"location":"static_test/3.2-review-process/#324-applying-review-techniques","text":"","title":"3.2.4 - Applying Review Techniques"},{"location":"static_test/3.2-review-process/#325-success-factors-for-reviews","text":"Each review has clear objectives, defined during review planning, and used as measurable exit criteria Review types are applied which are suitable to achieve the objectives and are appropriate to the type and level of software work products and participants Any review techniques used, such as checklist-based or role-based reviewing, are suitable for effective defect identification in the work product to be reviewed Any checklists used address the main risks and are up to date Large documents are written and reviewed in small chunks, so that quality control is exercised by providing authors early and frequent feedback on defects Participants have adequate time to prepare Reviews are scheduled with adequate notice","title":"3.2.5 - Success Factors for Reviews"},{"location":"test_management/1.-content/","text":"Test Management 5.1 - Test Organization 5.1.1 - Independent Testing 5.1.2 - Tasks of the Test Manager and Tester 5.2 - Test Planning and Estimation 5.2.1 - Purpose and content of a Test Plan 5.2.2 - Test Strategy and Test Approach 5.2.3 - Entry Criteria and Exit Criteria (DoR & DoD) 5.2.4 - Test Execution Schedule 5.2.5 - Factors Influencing the Test Effort 5.2.6 - Test Estimation Techniques 5.3 - Test Monitoring and Control 5.3.1 - Metrics used in Testing 5.3.2 - Purposes, Contents, and Audience for Test Reports 5.4 - Configuration Management 5.5 - Risk and Testing 5.5.1 - Definition of Risk 5.5.2 - Product and Project Risks 5.5.3 - Risk-based testing and Product Quality 5.6 - Defects Management","title":"1.-Content"},{"location":"test_management/1.-content/#test-management","text":"5.1 - Test Organization 5.1.1 - Independent Testing 5.1.2 - Tasks of the Test Manager and Tester 5.2 - Test Planning and Estimation 5.2.1 - Purpose and content of a Test Plan 5.2.2 - Test Strategy and Test Approach 5.2.3 - Entry Criteria and Exit Criteria (DoR & DoD) 5.2.4 - Test Execution Schedule 5.2.5 - Factors Influencing the Test Effort 5.2.6 - Test Estimation Techniques 5.3 - Test Monitoring and Control 5.3.1 - Metrics used in Testing 5.3.2 - Purposes, Contents, and Audience for Test Reports 5.4 - Configuration Management 5.5 - Risk and Testing 5.5.1 - Definition of Risk 5.5.2 - Product and Project Risks 5.5.3 - Risk-based testing and Product Quality 5.6 - Defects Management","title":"Test Management"},{"location":"test_management/5.1-test-org/","text":"5.1 - Test Organization 5.1.1 - Independent Testing 5.1.2 - Tasks of the Test Manager and Tester","title":"5.1-Test organization"},{"location":"test_management/5.1-test-org/#51-test-organization","text":"","title":"5.1 - Test Organization"},{"location":"test_management/5.1-test-org/#511-independent-testing","text":"","title":"5.1.1 - Independent Testing"},{"location":"test_management/5.1-test-org/#512-tasks-of-the-test-manager-and-tester","text":"","title":"5.1.2 - Tasks of the Test Manager and Tester"},{"location":"test_management/5.2-test-plan-estim/","text":"5.2.1 - Purpose and content of a Test Plan 5.2.2 - Test Strategy and Test Approach 5.2.3 - Entry Criteria and Exit Criteria (DoR & DoD) 5.2.4 - Test Execution Schedule 5.2.5 - Factors Influencing the Test Effort 5.2.6 - Test Estimation Techniques","title":"5.2-Test plan estimation"},{"location":"test_management/5.2-test-plan-estim/#521-purpose-and-content-of-a-test-plan","text":"","title":"5.2.1 - Purpose and content of a Test Plan"},{"location":"test_management/5.2-test-plan-estim/#522-test-strategy-and-test-approach","text":"","title":"5.2.2 - Test Strategy and Test Approach"},{"location":"test_management/5.2-test-plan-estim/#523-entry-criteria-and-exit-criteria-dor-dod","text":"","title":"5.2.3 - Entry Criteria and Exit Criteria (DoR &amp; DoD)"},{"location":"test_management/5.2-test-plan-estim/#524-test-execution-schedule","text":"","title":"5.2.4 - Test Execution Schedule"},{"location":"test_management/5.2-test-plan-estim/#525-factors-influencing-the-test-effort","text":"","title":"5.2.5 - Factors Influencing the Test Effort"},{"location":"test_management/5.2-test-plan-estim/#526-test-estimation-techniques","text":"","title":"5.2.6 - Test Estimation Techniques"},{"location":"test_management/5.3-test-mon-control/","text":"5.3.1 - Metrics used in Testing 5.3.2 - Purposes, Contents, and Audience for Test Reports","title":"5.3-Test monitoring & control"},{"location":"test_management/5.3-test-mon-control/#531-metrics-used-in-testing","text":"","title":"5.3.1 - Metrics used in Testing"},{"location":"test_management/5.3-test-mon-control/#532-purposes-contents-and-audience-for-test-reports","text":"","title":"5.3.2 - Purposes, Contents, and Audience for Test Reports"},{"location":"test_management/5.4-config-manage/","text":"5.4 - Configuration Management","title":"5.4-Config management"},{"location":"test_management/5.4-config-manage/#54-configuration-management","text":"","title":"5.4 - Configuration Management"},{"location":"test_management/5.5-risk-testing/","text":"5.5.1 - Definition of Risk 5.5.2 - Product and Project Risks 5.5.3 - Risk-based testing and Product Quality","title":"5.5-Risk testing"},{"location":"test_management/5.5-risk-testing/#551-definition-of-risk","text":"","title":"5.5.1 - Definition of Risk"},{"location":"test_management/5.5-risk-testing/#552-product-and-project-risks","text":"","title":"5.5.2 - Product and Project Risks"},{"location":"test_management/5.5-risk-testing/#553-risk-based-testing-and-product-quality","text":"","title":"5.5.3 - Risk-based testing and Product Quality"},{"location":"test_management/5.6-defects-manage/","text":"5.6 - Defects Management","title":"5.6-Defects management"},{"location":"test_management/5.6-defects-manage/#56-defects-management","text":"","title":"5.6 - Defects Management"},{"location":"test_techniques/1.-content/","text":"Test Techniques 4.1 - Categories of Test Techniques 4.1.1 - Categories of Test Techniques and Test Characteristics 4.2 - Black-Box Test Techniques 4.2.1 - Equivalence Partitioning 4.2.2 - Boundary Value Analysis 4.2.3 - Decision Table Testing 4.2.4 - State Transition Testing 4.2.5 - Use Case Testing 4.3 - White Box techniques 4.3.1 - Statement Testing and coverage 4.3.2 - Decision Testing and coverage 4.2.4 - The value of Statement and Decision Testing 4.4 - Experience-based techniques 4.4.1 - Error guessing 4.4.1 - Exploratory testing 4.4.1 - Checklist-based","title":"1.-Content"},{"location":"test_techniques/1.-content/#test-techniques","text":"4.1 - Categories of Test Techniques 4.1.1 - Categories of Test Techniques and Test Characteristics 4.2 - Black-Box Test Techniques 4.2.1 - Equivalence Partitioning 4.2.2 - Boundary Value Analysis 4.2.3 - Decision Table Testing 4.2.4 - State Transition Testing 4.2.5 - Use Case Testing 4.3 - White Box techniques 4.3.1 - Statement Testing and coverage 4.3.2 - Decision Testing and coverage 4.2.4 - The value of Statement and Decision Testing 4.4 - Experience-based techniques 4.4.1 - Error guessing 4.4.1 - Exploratory testing 4.4.1 - Checklist-based","title":"Test Techniques"},{"location":"test_techniques/4.1-cat-test-tech/","text":"4.1.1 - Categories of Test Techniques and Test Characteristics","title":"4.1-Categories"},{"location":"test_techniques/4.1-cat-test-tech/#411-categories-of-test-techniques-and-test-characteristics","text":"","title":"4.1.1 - Categories of Test Techniques and Test Characteristics"},{"location":"test_techniques/4.2-black-box-tech-tecn/","text":"Example : Introduction: Black-Box Testing, which is also known as specification-based testing, analyses the functionality of a software/application without knowing much about the internal structure/design of the item. The purpose of this method is to check the functionality of the system as a whole to make sure that it works correctly and meets user demands. Test Techniques 4.2.1 - Equivalence Partitioning Definition: In equivalence partitioning, input values to the system or application are divided into different partitions/group based on its similarity in the outcome. So instead of using each and every input value, you can use a value from each partition/group which covers all possible scenarios, to execute test cases. Test Scenario Let\u2019s suppose you are testing a machine that scores exam papers and assigns grades. Based on the score achieved the grades are as follows: 1-49 = F, 50-59 = D-, 60-69 = D, 70-79 = C, 80-89 = B, 90-100=A If you apply equivalence partitioning, how many test cases will you need to achieve minimum test coverage? Explanation From the example we can draw the following \u201cNumber Line\u201d where we will find out that we have 6 Valid Partitions [From 1 to 6 ] and 2 Invalid Partitions [7 & 8 ], so in total we have \"8 Partitions\". correct answer: 8 4.2.2 - Boundary Value Analysis Definition: If the input is within the boundary value, it is considered \u2018Positive testing.\u2019 If the input is outside of the boundary value, it is considered \u2018Negative testing.\u2019 It includes maximum, minimum, inside or outside edge, typical values or error values. Test Scenario You are testing a scale system that determines shipping rates for a regional web-based auto parts distributor. Due to regulations, shipments cannot exceed 100 lbs. You want to include boundary value analysis as part of your black-box test design. How many tests will you need to execute to achieve 100% boundary value analysis? Example explanation: From the example we can draw the following \u201cNumber Line\u201d, where we will find out that we have 8 Valid Boundaries [ 1,10, 11,25, 26,50, 51,100 ] and 2 Invalid Boundaries [ 0 , 101 ] so in total we have \"10 Boundaries\". correct answer: 10 From the example we can draw the following \u201cNumber Line\u201d, where we will find out that we have 8 Valid Boundaries [ 1,10, 11,25, 26,50, 51,100 ] and 2 Invalid Boundaries [ 0 , 101 ] so in total we have \"10 Boundaries\". 4.2.3 - Decision Table Testing Definition: A Decision Table basically is a tabular representation of different possible conditions ---> (inputs) versus test actions ---> outputs . In this technique, we deal with a different combination of input values. This helps tester identify all input values if he has overlooked any. Hence its also referred to as a cause-effect table technique. Test Scenario Given this decision table, what is the expected result for the following test cases? TCI: A 26-year-old on business but with violations or accidents on his driving record TC2: A 62-year-old tourist with a clean driving record Example Explanation: correct answer: TCI: Don't supply car with premium charge; TC2: Supply car with no premium charge By analyzing the two given test cases and the table you will find out that : Test case (1) test the Rule number (2) which means that the expected result from this test case is to (Don\u2019t Supply car \u201cwith no premium charge\u201d). Test case (2) test the Rule number (3) which means that the expected result from this test case is to (Supply car with no premium charge). Based on this, you will find out that the only relevant answer is (TC1:Don\u2019t Supply car ,TC2:Supply car with no premium charge ). 4.2.4 - State Transition Testing Definition In this approach, the tester analyzes the behavior of an application under test for different input conditions in a sequence. You can provide positive as well as negative values to check how the application responds. You can apply this technique when an application/system gives a different output for the same input, depending on what has happened in the earlier state. We call such a system as a finite state system. Test Scenario Which of the following statements about the given state table is TRUE? Explanation Correct answer: The state table represents all possible single transitions. 4.2.5 - Use Case Testing Definition: It depends on \u2018User Actions\u2019 and \u2018Response of System\u2019 to those User Actions. This technique is completely functional testing technique, as in no programming skill is required. You can follow these three simple steps to perform use case testing: Identify all the possible scenarios from a Use Case For each scenario, define a test case and a condition for that test case to be executed For each scenario, determine the test data for the test Test Scenario Explanation","title":"4.2-Black Box"},{"location":"test_techniques/4.2-black-box-tech-tecn/#example","text":"","title":"Example:"},{"location":"test_techniques/4.2-black-box-tech-tecn/#introduction","text":"Black-Box Testing, which is also known as specification-based testing, analyses the functionality of a software/application without knowing much about the internal structure/design of the item. The purpose of this method is to check the functionality of the system as a whole to make sure that it works correctly and meets user demands.","title":"Introduction:"},{"location":"test_techniques/4.2-black-box-tech-tecn/#test-techniques","text":"","title":"Test Techniques"},{"location":"test_techniques/4.2-black-box-tech-tecn/#421-equivalence-partitioning","text":"","title":"4.2.1 - Equivalence Partitioning"},{"location":"test_techniques/4.2-black-box-tech-tecn/#definition","text":"In equivalence partitioning, input values to the system or application are divided into different partitions/group based on its similarity in the outcome. So instead of using each and every input value, you can use a value from each partition/group which covers all possible scenarios, to execute test cases.","title":"Definition:"},{"location":"test_techniques/4.2-black-box-tech-tecn/#test-scenario","text":"Let\u2019s suppose you are testing a machine that scores exam papers and assigns grades. Based on the score achieved the grades are as follows: 1-49 = F, 50-59 = D-, 60-69 = D, 70-79 = C, 80-89 = B, 90-100=A If you apply equivalence partitioning, how many test cases will you need to achieve minimum test coverage?","title":"Test Scenario"},{"location":"test_techniques/4.2-black-box-tech-tecn/#explanation","text":"From the example we can draw the following \u201cNumber Line\u201d where we will find out that we have 6 Valid Partitions [From 1 to 6 ] and 2 Invalid Partitions [7 & 8 ], so in total we have \"8 Partitions\". correct answer: 8","title":"Explanation"},{"location":"test_techniques/4.2-black-box-tech-tecn/#422-boundary-value-analysis","text":"","title":"4.2.2 - Boundary Value Analysis"},{"location":"test_techniques/4.2-black-box-tech-tecn/#definition_1","text":"If the input is within the boundary value, it is considered \u2018Positive testing.\u2019 If the input is outside of the boundary value, it is considered \u2018Negative testing.\u2019 It includes maximum, minimum, inside or outside edge, typical values or error values.","title":"Definition:"},{"location":"test_techniques/4.2-black-box-tech-tecn/#test-scenario_1","text":"You are testing a scale system that determines shipping rates for a regional web-based auto parts distributor. Due to regulations, shipments cannot exceed 100 lbs. You want to include boundary value analysis as part of your black-box test design. How many tests will you need to execute to achieve 100% boundary value analysis?","title":"Test Scenario"},{"location":"test_techniques/4.2-black-box-tech-tecn/#example_1","text":"explanation: From the example we can draw the following \u201cNumber Line\u201d, where we will find out that we have 8 Valid Boundaries [ 1,10, 11,25, 26,50, 51,100 ] and 2 Invalid Boundaries [ 0 , 101 ] so in total we have \"10 Boundaries\". correct answer: 10 From the example we can draw the following \u201cNumber Line\u201d, where we will find out that we have 8 Valid Boundaries [ 1,10, 11,25, 26,50, 51,100 ] and 2 Invalid Boundaries [ 0 , 101 ] so in total we have \"10 Boundaries\".","title":"Example"},{"location":"test_techniques/4.2-black-box-tech-tecn/#423-decision-table-testing","text":"","title":"4.2.3 - Decision Table Testing"},{"location":"test_techniques/4.2-black-box-tech-tecn/#definition_2","text":"A Decision Table basically is a tabular representation of different possible conditions ---> (inputs) versus test actions ---> outputs . In this technique, we deal with a different combination of input values. This helps tester identify all input values if he has overlooked any. Hence its also referred to as a cause-effect table technique.","title":"Definition:"},{"location":"test_techniques/4.2-black-box-tech-tecn/#test-scenario_2","text":"Given this decision table, what is the expected result for the following test cases? TCI: A 26-year-old on business but with violations or accidents on his driving record TC2: A 62-year-old tourist with a clean driving record","title":"Test Scenario"},{"location":"test_techniques/4.2-black-box-tech-tecn/#example_2","text":"Explanation: correct answer: TCI: Don't supply car with premium charge; TC2: Supply car with no premium charge By analyzing the two given test cases and the table you will find out that : Test case (1) test the Rule number (2) which means that the expected result from this test case is to (Don\u2019t Supply car \u201cwith no premium charge\u201d). Test case (2) test the Rule number (3) which means that the expected result from this test case is to (Supply car with no premium charge). Based on this, you will find out that the only relevant answer is (TC1:Don\u2019t Supply car ,TC2:Supply car with no premium charge ).","title":"Example"},{"location":"test_techniques/4.2-black-box-tech-tecn/#424-state-transition-testing","text":"","title":"4.2.4 - State Transition Testing"},{"location":"test_techniques/4.2-black-box-tech-tecn/#definition_3","text":"In this approach, the tester analyzes the behavior of an application under test for different input conditions in a sequence. You can provide positive as well as negative values to check how the application responds. You can apply this technique when an application/system gives a different output for the same input, depending on what has happened in the earlier state. We call such a system as a finite state system.","title":"Definition"},{"location":"test_techniques/4.2-black-box-tech-tecn/#test-scenario_3","text":"Which of the following statements about the given state table is TRUE?","title":"Test Scenario"},{"location":"test_techniques/4.2-black-box-tech-tecn/#explanation_1","text":"Correct answer: The state table represents all possible single transitions.","title":"Explanation"},{"location":"test_techniques/4.2-black-box-tech-tecn/#425-use-case-testing","text":"","title":"4.2.5 - Use Case Testing"},{"location":"test_techniques/4.2-black-box-tech-tecn/#definition_4","text":"It depends on \u2018User Actions\u2019 and \u2018Response of System\u2019 to those User Actions. This technique is completely functional testing technique, as in no programming skill is required. You can follow these three simple steps to perform use case testing: Identify all the possible scenarios from a Use Case For each scenario, define a test case and a condition for that test case to be executed For each scenario, determine the test data for the test","title":"Definition:"},{"location":"test_techniques/4.2-black-box-tech-tecn/#test-scenario_4","text":"","title":"Test Scenario"},{"location":"test_techniques/4.2-black-box-tech-tecn/#explanation_2","text":"","title":"Explanation"},{"location":"test_techniques/4.3-white-box-tech/","text":"Definition: is a testing technique which evaluates the code and the internal structure of a program. When you know the internal structure of a product, tests can be conducted to ensure that the internal operations performed according to the specification. And all internal components have been adequately exercised. Test Techniques 4.3.1 - Statement Testing and coverage Definition: \u201cStatement Coverage\u201d , as the name itself suggests, it is the method of validating whether each and every line of the code is executed at least once Test Scenario: Explanation Based on the above image: To make a 100% Statement Coverage you need to trigger the statements [Statement a ,Statement b, Statement c ] For Statement Coverage: Since you can\u2019t trigger the three statements with a single execution, the minimum test cases required to cover all the possible sequences of statements are 2 test cases. TC1 : day = Monday, will trigger the (Statement a ) TC2 : day = Tuesday, will trigger the (Statement b ,Statement c ) So the minimum test cases required to cover all the possible sequences of statements are 2 test cases. 4.3.2 - Decision Testing and coverage Definition: Test Scenario: Example Explanation Minimum Tests required for statement coverage and branch coverage 4.2.4 - The value of Statement and Decision Testing Defintiion: Test Scenario: Example","title":"4.3-White Box"},{"location":"test_techniques/4.3-white-box-tech/#definition","text":"is a testing technique which evaluates the code and the internal structure of a program. When you know the internal structure of a product, tests can be conducted to ensure that the internal operations performed according to the specification. And all internal components have been adequately exercised.","title":"Definition:"},{"location":"test_techniques/4.3-white-box-tech/#test-techniques","text":"","title":"Test Techniques"},{"location":"test_techniques/4.3-white-box-tech/#431-statement-testing-and-coverage","text":"","title":"4.3.1 - Statement Testing and coverage"},{"location":"test_techniques/4.3-white-box-tech/#definition_1","text":"\u201cStatement Coverage\u201d , as the name itself suggests, it is the method of validating whether each and every line of the code is executed at least once","title":"Definition:"},{"location":"test_techniques/4.3-white-box-tech/#test-scenario","text":"","title":"Test Scenario:"},{"location":"test_techniques/4.3-white-box-tech/#explanation","text":"Based on the above image: To make a 100% Statement Coverage you need to trigger the statements [Statement a ,Statement b, Statement c ] For Statement Coverage: Since you can\u2019t trigger the three statements with a single execution, the minimum test cases required to cover all the possible sequences of statements are 2 test cases. TC1 : day = Monday, will trigger the (Statement a ) TC2 : day = Tuesday, will trigger the (Statement b ,Statement c ) So the minimum test cases required to cover all the possible sequences of statements are 2 test cases.","title":"Explanation"},{"location":"test_techniques/4.3-white-box-tech/#432-decision-testing-and-coverage","text":"","title":"4.3.2 - Decision Testing and coverage"},{"location":"test_techniques/4.3-white-box-tech/#definition_2","text":"","title":"Definition:"},{"location":"test_techniques/4.3-white-box-tech/#test-scenario_1","text":"","title":"Test Scenario:"},{"location":"test_techniques/4.3-white-box-tech/#example","text":"","title":"Example"},{"location":"test_techniques/4.3-white-box-tech/#explanation_1","text":"Minimum Tests required for statement coverage and branch coverage","title":"Explanation"},{"location":"test_techniques/4.3-white-box-tech/#424-the-value-of-statement-and-decision-testing","text":"","title":"4.2.4 - The value of Statement and Decision Testing"},{"location":"test_techniques/4.3-white-box-tech/#defintiion","text":"","title":"Defintiion:"},{"location":"test_techniques/4.3-white-box-tech/#test-scenario_2","text":"","title":"Test Scenario:"},{"location":"test_techniques/4.3-white-box-tech/#example_1","text":"","title":"Example"},{"location":"test_techniques/4.4-exp-based-tech/","text":"4.4.1 - Error guessing Error guessing is a technique used to anticipate the occurrence of errors, defects, and failures, based on the tester\u2019s knowledge, including: How the application has worked in the past What kind of errors tend to be made Failures that have occurred in other applications A methodical approach to the error guessing technique is to create a list of possible errors, defects, and failures, and design tests that will expose those failures and the defects that caused them. 4.4.1 - Exploratory testing In exploratory testing, informal (not pre-defined) tests are designed, executed, logged, and evaluated dynamically during test execution. The test results are used to learn more about the component or system, and to create tests for the areas that may need more testing. Exploratory testing is most useful when there are few or inadequate specifications or significant time pressure on testing or to complement other more formal testing techniques. In practice, can incorporate the use of other techniques: black-box white-box experience-based. 4.4.1 - Checklist-based In checklist-based testing, testers design, implement, and execute tests to cover test conditions found in a checklist. Such checklists can be built based on experience, knowledge about what is important for the user, or an understanding of why and how software fails. Checklists can be created to support various test types, including functional and non-functional testing. In the absence of detailed test cases, checklist-based testing can provide guidelines and a degree of consistency.","title":"4.4-Experience Based"},{"location":"test_techniques/4.4-exp-based-tech/#441-error-guessing","text":"Error guessing is a technique used to anticipate the occurrence of errors, defects, and failures, based on the tester\u2019s knowledge, including: How the application has worked in the past What kind of errors tend to be made Failures that have occurred in other applications A methodical approach to the error guessing technique is to create a list of possible errors, defects, and failures, and design tests that will expose those failures and the defects that caused them.","title":"4.4.1 - Error guessing"},{"location":"test_techniques/4.4-exp-based-tech/#441-exploratory-testing","text":"In exploratory testing, informal (not pre-defined) tests are designed, executed, logged, and evaluated dynamically during test execution. The test results are used to learn more about the component or system, and to create tests for the areas that may need more testing. Exploratory testing is most useful when there are few or inadequate specifications or significant time pressure on testing or to complement other more formal testing techniques. In practice, can incorporate the use of other techniques: black-box white-box experience-based.","title":"4.4.1 - Exploratory testing"},{"location":"test_techniques/4.4-exp-based-tech/#441-checklist-based","text":"In checklist-based testing, testers design, implement, and execute tests to cover test conditions found in a checklist. Such checklists can be built based on experience, knowledge about what is important for the user, or an understanding of why and how software fails. Checklists can be created to support various test types, including functional and non-functional testing. In the absence of detailed test cases, checklist-based testing can provide guidelines and a degree of consistency.","title":"4.4.1 - Checklist-based"},{"location":"test_techniques/temporal/","text":"Testing without knowing the internal structure of the system. Types of Black box testing Black box testing can be applied to three main types of tests: functional , non-functional , and regression testing . Functional testing It can check if it\u00b4s possible log in using correct credentials or not if are wrong. Non functional testing It can check for security vulnerabilities. Performance under expected loads Usable and easy to understand for users Compatible with relevant devices, screen sizes, browsers or O.S. Regression testing Regression can be applied for functional and non-functional. Black box can check if a new version of software load slower as an example. Black Box testing techniques: Equivalence Partitioning Boundary Value Analysis Decision Table Testing Error guessing","title":"Temporal"},{"location":"test_techniques/temporal/#types-of-black-box-testing","text":"Black box testing can be applied to three main types of tests: functional , non-functional , and regression testing .","title":"Types of Black box testing"},{"location":"test_techniques/temporal/#functional-testing","text":"It can check if it\u00b4s possible log in using correct credentials or not if are wrong.","title":"Functional testing"},{"location":"test_techniques/temporal/#non-functional-testing","text":"It can check for security vulnerabilities. Performance under expected loads Usable and easy to understand for users Compatible with relevant devices, screen sizes, browsers or O.S.","title":"Non functional testing"},{"location":"test_techniques/temporal/#regression-testing","text":"Regression can be applied for functional and non-functional. Black box can check if a new version of software load slower as an example.","title":"Regression testing"},{"location":"test_techniques/temporal/#black-box-testing-techniques","text":"Equivalence Partitioning Boundary Value Analysis Decision Table Testing Error guessing","title":"Black Box testing techniques:"},{"location":"test_types/change_rel/","text":"Regression testing is a type of testing aimed at checking changes made in an application or the environment (fixing a defect, merging code, migrating to another operating system, database, web server or application server) to confirm the fact that the existing functionality is working as before. Confirmation testing Confirms that the original defect has been successfully fixed. Regression testing Confirms that the changes have not caused any side-defects. Tools Selenium Katalon Studio AdventNet QEngine Regression Tester vTest Watir actiWate","title":"Change rel"},{"location":"test_types/change_rel/#confirmation-testing","text":"Confirms that the original defect has been successfully fixed.","title":"Confirmation testing"},{"location":"test_types/change_rel/#regression-testing","text":"Confirms that the changes have not caused any side-defects.","title":"Regression testing"},{"location":"test_types/change_rel/#tools","text":"Selenium Katalon Studio AdventNet QEngine Regression Tester vTest Watir actiWate","title":"Tools"},{"location":"test_types/func_test/","text":"Is conducted to verify that functions of a system are working as specified. There are a variety of functional testing strategies, and the best way to ensure functional test coverage is a mix of manual and automated testing. The most common functional testing strategies are black-box testing methods wherein the tester does not need to review the internal source code, but validates functionality by testing various input combinations. Main features Testing what the system should do Usually answered with (Yes/No) Functional tests should be performed at all test levels Can run manual and automated tests Login example Navigate to login page In the \u2019email\u2019 field, enter the email address of the registered user Click the \u2018Next\u2019 button Enter the password of the registered * user Click \u2018Sign In\u2019 If success, go to next page If not, throw error message and go back to login page Tools Selenium Cypress MicroFocus Katalon","title":"Func test"},{"location":"test_types/func_test/#main-features","text":"Testing what the system should do Usually answered with (Yes/No) Functional tests should be performed at all test levels Can run manual and automated tests","title":"Main features"},{"location":"test_types/func_test/#login-example","text":"Navigate to login page In the \u2019email\u2019 field, enter the email address of the registered user Click the \u2018Next\u2019 button Enter the password of the registered * user Click \u2018Sign In\u2019 If success, go to next page If not, throw error message and go back to login page","title":"Login example"},{"location":"test_types/func_test/#tools","text":"Selenium Cypress MicroFocus Katalon","title":"Tools"},{"location":"test_types/non_func_test/","text":"Main features Testing how the system performs Hard to answer with Yes/No Usually measured as a range or metric May be performed at all test levels Mostly for automated tests Typical questions for non-functional test: How many concurrent users can the system support? How long is the data held locally before it is archived? How long will it take for a page to download? How many transactions can occur in a period of time? What is the maximum number of transactions that can take place? Tools Jmeter Loadrunner Webserver Stress tool","title":"Non func test"},{"location":"test_types/non_func_test/#main-features","text":"Testing how the system performs Hard to answer with Yes/No Usually measured as a range or metric May be performed at all test levels Mostly for automated tests","title":"Main features"},{"location":"test_types/non_func_test/#typical-questions-for-non-functional-test","text":"How many concurrent users can the system support? How long is the data held locally before it is archived? How long will it take for a page to download? How many transactions can occur in a period of time? What is the maximum number of transactions that can take place?","title":"Typical questions for non-functional test:"},{"location":"test_types/non_func_test/#tools","text":"Jmeter Loadrunner Webserver Stress tool","title":"Tools"},{"location":"tool_support/1.-content/","text":"Tool Support Testing 6.1 - Test Tool Consideration 6.1.1 - Test Tool Classification 6.1.2 - Benefits and Risks of Test Automation 6.1.3 - Special Considerations for Test Execution and Test Management Tools 6.2 - Effective use of Tools 6.2.1 - Main Principles for Tools Selection 6.2.2 - Pilot Projects for Introducing a Tool into an Organization 6.2.3 - Success Factors for Tools","title":"1.-Content"},{"location":"tool_support/1.-content/#tool-support-testing","text":"6.1 - Test Tool Consideration 6.1.1 - Test Tool Classification 6.1.2 - Benefits and Risks of Test Automation 6.1.3 - Special Considerations for Test Execution and Test Management Tools 6.2 - Effective use of Tools 6.2.1 - Main Principles for Tools Selection 6.2.2 - Pilot Projects for Introducing a Tool into an Organization 6.2.3 - Success Factors for Tools","title":"Tool Support Testing"},{"location":"tool_support/6.1-test-tool-consid/","text":"6.1.1 - Test Tool Classification Tools are classified according to the testing activities that they support but those that support more than one activity are classified in the most closely associated. Tool support for management of testing and testware Example of tools: Tool support for static testing Static testing tools are associated with the activities related to analyse the code withouw executing it. Example of tools: Tool support for test design and implementation Include test cases, test procedures and test data. Example of tools: Model-Based testing tools Test data preparation tools In some cases, tools that support test design and implementation may also support test execution and logging, or provide their outputs directly to other tools that support test execution and logging Tool support for test execution and logging Example of tools: Test execution tools (e.g., to run regression tests) Coverage tools (e.g., requirements coverage, code coverage (D)) Test harnesses (D) Tool support for Performance measurement and Dynamic analysis Are \u2018dynamic\u2019 because they require the code to be in a running state Example of tools: Performance testing tools Dynamic analysis tools (D) 6.1.2 - Benefits and Risks of Test Automation Simply acquiring a tool does not guarantee success. Each new tool introduced into an organization will require effort to achieve real and lasting benefits. Potential benefits of using tools to support test execution include: Reduction in repetitive manual work (e.g., running regression tests, environment set up/tear down tasks, re-entering the same test data, and checking against coding standards) Greater consistency and repeatability More objective assessment (e.g., static measures, coverage) Easier access to information about testing (e.g., statistics and graphs about test progress, defect rates and performance) Potential risks of using tools to support test execution include: The time and effort needed to achieve significant and continuing benefits from the tool may be under-estimated A new platform or technology may not be supported by the tool The effort required to maintain the test work products generated by the tool may be underestimated Expectations for the tool may be unrealistic. 6.1.3 - Special Considerations for Test Execution and Test Management Tools Test Execution tools: Capturing test approach Data-driven test approach: Keyword-driven test approach: Test Management tools Are useful for: Fits the needs of the organization To maintain consistent traceability to requirements in a requirements management tool To link with test object version information","title":"6.1-Test tools consideration"},{"location":"tool_support/6.1-test-tool-consid/#611-test-tool-classification","text":"Tools are classified according to the testing activities that they support but those that support more than one activity are classified in the most closely associated.","title":"6.1.1 - Test Tool Classification"},{"location":"tool_support/6.1-test-tool-consid/#tool-support-for-management-of-testing-and-testware","text":"","title":"Tool support for management of testing and testware"},{"location":"tool_support/6.1-test-tool-consid/#example-of-tools","text":"","title":"Example of tools:"},{"location":"tool_support/6.1-test-tool-consid/#tool-support-for-static-testing","text":"Static testing tools are associated with the activities related to analyse the code withouw executing it.","title":"Tool support for static testing"},{"location":"tool_support/6.1-test-tool-consid/#example-of-tools_1","text":"","title":"Example of tools:"},{"location":"tool_support/6.1-test-tool-consid/#tool-support-for-test-design-and-implementation","text":"Include test cases, test procedures and test data.","title":"Tool support for test design and implementation"},{"location":"tool_support/6.1-test-tool-consid/#example-of-tools_2","text":"Model-Based testing tools Test data preparation tools In some cases, tools that support test design and implementation may also support test execution and logging, or provide their outputs directly to other tools that support test execution and logging","title":"Example of tools:"},{"location":"tool_support/6.1-test-tool-consid/#tool-support-for-test-execution-and-logging","text":"","title":"Tool support for test execution and logging"},{"location":"tool_support/6.1-test-tool-consid/#example-of-tools_3","text":"Test execution tools (e.g., to run regression tests) Coverage tools (e.g., requirements coverage, code coverage (D)) Test harnesses (D)","title":"Example of tools:"},{"location":"tool_support/6.1-test-tool-consid/#tool-support-for-performance-measurement-and-dynamic-analysis","text":"Are \u2018dynamic\u2019 because they require the code to be in a running state","title":"Tool support for Performance measurement and Dynamic analysis"},{"location":"tool_support/6.1-test-tool-consid/#example-of-tools_4","text":"Performance testing tools Dynamic analysis tools (D)","title":"Example of tools:"},{"location":"tool_support/6.1-test-tool-consid/#612-benefits-and-risks-of-test-automation","text":"Simply acquiring a tool does not guarantee success. Each new tool introduced into an organization will require effort to achieve real and lasting benefits. Potential benefits of using tools to support test execution include: Reduction in repetitive manual work (e.g., running regression tests, environment set up/tear down tasks, re-entering the same test data, and checking against coding standards) Greater consistency and repeatability More objective assessment (e.g., static measures, coverage) Easier access to information about testing (e.g., statistics and graphs about test progress, defect rates and performance) Potential risks of using tools to support test execution include: The time and effort needed to achieve significant and continuing benefits from the tool may be under-estimated A new platform or technology may not be supported by the tool The effort required to maintain the test work products generated by the tool may be underestimated Expectations for the tool may be unrealistic.","title":"6.1.2 - Benefits and Risks of Test Automation"},{"location":"tool_support/6.1-test-tool-consid/#613-special-considerations-for-test-execution-and-test-management-tools","text":"","title":"6.1.3 - Special Considerations for Test Execution and Test Management Tools"},{"location":"tool_support/6.1-test-tool-consid/#test-execution-tools","text":"Capturing test approach Data-driven test approach: Keyword-driven test approach:","title":"Test Execution tools:"},{"location":"tool_support/6.1-test-tool-consid/#test-management-tools","text":"Are useful for: Fits the needs of the organization To maintain consistent traceability to requirements in a requirements management tool To link with test object version information","title":"Test Management tools"},{"location":"tool_support/6.2-effective-use-tools/","text":"6.2.1 - Main Principles for Tools Selection Assessment of the maturity of the own organization , its strengths and weaknesses Identification of opportunities for an improved test process supported by tools Understanding of the technologies used by the test object(s), in order to select a tool that is compatible with that technology Understanding the build and continuous integration tools already in use within the organization, in order to ensure tool compatibility and integration Evaluation of the tool against clear requirements and objective criteria Consideration of whether or not the tool is available for a free trial period (and for how long) 6.2.2 - Pilot Projects for Introducing a Tool into an Organization Gaining in-depth knowledge about the tool, understanding both its strengths and weaknesses Evaluating how the tool fits with existing processes and practices, and determining what would need to change Deciding on standard ways of using, managing, storing, and maintaining the tool and the test work products (e.g., deciding on naming conventions for files and tests, selecting coding standards, creating libraries and defining the modularity of test suites) Assessing whether the benefits will be achieved at reasonable cost Understanding the metrics that you wish the tool to collect and report, and configuring the tool to ensure these metrics can be captured and reported 6.2.3 - Success Factors for Tools Rolling out the tool to the rest of the organization incrementally Adapting and improving processes to fit with the use of the tool Providing training, coaching, and mentoring for tool users Defining guidelines for the use of the tool (e.g., internal standards for automation) Implementing a way to gather usage information from the actual use of the tool Monitoring tool use and benefits Providing support to the users of a given tool Gathering lessons learned from all users","title":"6.2-Effective use of tools"},{"location":"tool_support/6.2-effective-use-tools/#621-main-principles-for-tools-selection","text":"Assessment of the maturity of the own organization , its strengths and weaknesses Identification of opportunities for an improved test process supported by tools Understanding of the technologies used by the test object(s), in order to select a tool that is compatible with that technology Understanding the build and continuous integration tools already in use within the organization, in order to ensure tool compatibility and integration Evaluation of the tool against clear requirements and objective criteria Consideration of whether or not the tool is available for a free trial period (and for how long)","title":"6.2.1 - Main Principles for Tools Selection"},{"location":"tool_support/6.2-effective-use-tools/#622-pilot-projects-for-introducing-a-tool-into-an-organization","text":"Gaining in-depth knowledge about the tool, understanding both its strengths and weaknesses Evaluating how the tool fits with existing processes and practices, and determining what would need to change Deciding on standard ways of using, managing, storing, and maintaining the tool and the test work products (e.g., deciding on naming conventions for files and tests, selecting coding standards, creating libraries and defining the modularity of test suites) Assessing whether the benefits will be achieved at reasonable cost Understanding the metrics that you wish the tool to collect and report, and configuring the tool to ensure these metrics can be captured and reported","title":"6.2.2 - Pilot Projects for Introducing a Tool into an Organization"},{"location":"tool_support/6.2-effective-use-tools/#623-success-factors-for-tools","text":"Rolling out the tool to the rest of the organization incrementally Adapting and improving processes to fit with the use of the tool Providing training, coaching, and mentoring for tool users Defining guidelines for the use of the tool (e.g., internal standards for automation) Implementing a way to gather usage information from the actual use of the tool Monitoring tool use and benefits Providing support to the users of a given tool Gathering lessons learned from all users","title":"6.2.3 - Success Factors for Tools"},{"location":"tool_support/man_vs_aut/","text":"Scenarios Manual Testing Scenarios Exploratory Testing This type of testing requires the tester\u2019s domain expertise, logical and creative thinking, past knowledge and experience. In this scenario, human skills are required to execute the testing process. Usability Testing In this testing manual approach is preferred as we need to evaluate how user-friendly, efficient and easy-to-use the application is from an end-user\u2019s perspective . Ad-hoc Testing It is a totally unplanned method of testing where the understanding and insight of the tester is the only important factor. Test Automation Scenarios Regression Testing Here, automated testing is suitable because of the frequent code changes and the ability to run the regressions in a timely manner. Load Testing Automated testing is also the best way to complete the testing efficiently when it comes to load testing. Performance Testing Testing which requires the simulation of thousands of concurrent users requires automation. This involves load, stress,volume etc.","title":"Man vs aut"},{"location":"tool_support/man_vs_aut/#scenarios","text":"","title":"Scenarios"},{"location":"tool_support/man_vs_aut/#manual-testing-scenarios","text":"Exploratory Testing This type of testing requires the tester\u2019s domain expertise, logical and creative thinking, past knowledge and experience. In this scenario, human skills are required to execute the testing process. Usability Testing In this testing manual approach is preferred as we need to evaluate how user-friendly, efficient and easy-to-use the application is from an end-user\u2019s perspective . Ad-hoc Testing It is a totally unplanned method of testing where the understanding and insight of the tester is the only important factor.","title":"Manual Testing Scenarios"},{"location":"tool_support/man_vs_aut/#test-automation-scenarios","text":"Regression Testing Here, automated testing is suitable because of the frequent code changes and the ability to run the regressions in a timely manner. Load Testing Automated testing is also the best way to complete the testing efficiently when it comes to load testing. Performance Testing Testing which requires the simulation of thousands of concurrent users requires automation. This involves load, stress,volume etc.","title":"Test Automation Scenarios"},{"location":"tool_support/test_tool_clas/","text":"Type of testing tools: Open-source: Appium Selenium Capybara testNG Katalon Studio Cypress testNG Jmeter Commercial tools IBM Rational Functional Tester (RFT) Automation Anywhere Custom tools The framework you create.","title":"Test tool clas"},{"location":"tool_support/test_tool_clas/#type-of-testing-tools","text":"","title":"Type of testing tools:"},{"location":"tool_support/test_tool_clas/#open-source","text":"Appium Selenium Capybara testNG Katalon Studio Cypress testNG Jmeter","title":"Open-source:"},{"location":"tool_support/test_tool_clas/#commercial-tools","text":"IBM Rational Functional Tester (RFT) Automation Anywhere","title":"Commercial tools"},{"location":"tool_support/test_tool_clas/#custom-tools","text":"The framework you create.","title":"Custom tools"},{"location":"tool_support/tool_selection/","text":"Considerations According to test experts, these are the things you need to consider when choosing your tools: 1.- Does your team possess the necessary skills to best utilize the tool? 2.- What is your team budget? 3.- What features to look for? Supported platforms Programming languages CI/CD integration capabilities Reporting functionality Complexity Cross-browser testing 4.- How difficult is script maintenance and reusability? 5.- How are the integration capabilities 6.- How and where can you get technical support?","title":"Tool selection"},{"location":"tool_support/tool_selection/#considerations","text":"According to test experts, these are the things you need to consider when choosing your tools: 1.- Does your team possess the necessary skills to best utilize the tool? 2.- What is your team budget? 3.- What features to look for? Supported platforms Programming languages CI/CD integration capabilities Reporting functionality Complexity Cross-browser testing 4.- How difficult is script maintenance and reusability? 5.- How are the integration capabilities 6.- How and where can you get technical support?","title":"Considerations"}]}